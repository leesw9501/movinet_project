{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "013fcc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch\n",
    "import transforms as T\n",
    "from movinets.config import _C\n",
    "import numpy as np\n",
    "from movinets import MoViNet\n",
    "import random\n",
    "import gc\n",
    "\n",
    "torch.manual_seed(97)\n",
    "num_frames = 16 # 16\n",
    "clip_steps = 2\n",
    "Bs_Train = 16\n",
    "Bs_Test = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f80fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict=dict()\n",
    "class_dict['normal']=0\n",
    "class_dict['assault']=1\n",
    "class_dict['fight']=2\n",
    "class_dict['burglary']=3\n",
    "class_dict['vandalism']=4\n",
    "class_dict['swoon']=5\n",
    "class_dict['wander']=6\n",
    "class_dict['trespass']=7\n",
    "class_dict['dump']=8\n",
    "class_dict['robbery']=9\n",
    "class_dict['datefight']=10\n",
    "class_dict['kidnap']=11\n",
    "class_dict['drunken']=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ea8de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i+1은 위 클래스 번호입니다.\n",
    "data_arr=[]\n",
    "label_arr=[]\n",
    "for i in range(6):\n",
    "    data_arr.append(np.load('../sampledata/sample_train_'+ str(i+1) +'_uint8.npy'))\n",
    "    label_arr.append(np.load('../sampledata/sample_label_'+ str(i+1) +'_uint8.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1f5ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1523, 16, 172, 172, 3)\n",
      "(1523,)\n",
      "(1541, 16, 172, 172, 3)\n",
      "(1541,)\n",
      "(1526, 16, 172, 172, 3)\n",
      "(1526,)\n",
      "(1665, 16, 172, 172, 3)\n",
      "(1665,)\n",
      "(1545, 16, 172, 172, 3)\n",
      "(1545,)\n",
      "(1539, 16, 172, 172, 3)\n",
      "(1539,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(data_arr[i].shape)\n",
    "    print(label_arr[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "707c0b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((data_arr[0], data_arr[1], data_arr[2],\n",
    "                       data_arr[3], data_arr[4], data_arr[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5add83c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab4b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.concatenate((label_arr[0], label_arr[1], label_arr[2],\n",
    "                        label_arr[3], label_arr[4], label_arr[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd2f6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio=[]\n",
    "for i in range(data.shape[0]):\n",
    "    audio.append([])\n",
    "    \n",
    "audio = np.array(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a9b391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9339, 16, 172, 172, 3)\n",
      "(9339,)\n",
      "(9339, 0)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(label.shape)\n",
    "print(audio.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e4856bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index=random.sample([i for i in range(data.shape[0])], int(data.shape[0]/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "718f3f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "933"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bde9969",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = torch.from_numpy(data[random_index].reshape(-1, 3, 16, 172, 172))\n",
    "val_audio = torch.from_numpy(audio[random_index]).reshape(int(data.shape[0]/10),1,0)\n",
    "val_label = torch.from_numpy(label[random_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99915dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.from_numpy(np.delete(data, random_index, axis=0).reshape(-1, 3, 16, 172, 172))\n",
    "train_audio = torch.from_numpy(np.delete(audio, random_index, axis=0)).reshape(data.shape[0]-int(data.shape[0]/10),1,0)\n",
    "train_label = torch.from_numpy(np.delete(label, random_index, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20a1ba7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8406, 3, 16, 172, 172])\n",
      "torch.Size([8406, 1, 0])\n",
      "torch.Size([8406])\n",
      "torch.Size([933, 3, 16, 172, 172])\n",
      "torch.Size([933, 1, 0])\n",
      "torch.Size([933])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_audio.shape)\n",
    "print(train_label.shape)\n",
    "\n",
    "print(val_data.shape)\n",
    "print(val_audio.shape)\n",
    "print(val_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdd0017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a8286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5fb6c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = torch.from_numpy(train.reshape(-1, 3, 16, 172, 172))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ddc7209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label = torch.from_numpy(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8eb7ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c5e6a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = torch.from_numpy(np.load('../sample_train_uint8.npy').reshape(9220, 3, 16, 172, 172))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "554a7940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label = torch.from_numpy(np.load('../sample_label_uint8.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88938c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\naudio=[]\\nfor i in range(train.shape[0]):\\n    audio.append([])\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "audio=[]\n",
    "for i in range(train.shape[0]):\n",
    "    audio.append([])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ad96a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\naudio = torch.from_numpy(np.array(audio)).reshape(train.shape[0],1,0)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "audio = torch.from_numpy(np.array(audio)).reshape(train.shape[0],1,0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c2a00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cctv():\n",
    "\n",
    "    def __init__(self, train_data, audio_data, label_data):\n",
    "        self.train = train_data\n",
    "        self.audio = audio_data\n",
    "        self.label = label_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.train.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.train[idx].float()/255, self.audio[idx], self.label[idx].long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21b3983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cctv_train = cctv(train_data, train_audio, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "959ad132",
   "metadata": {},
   "outputs": [],
   "source": [
    "cctv_val = cctv(val_data, val_audio, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cadfc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(cctv_train, batch_size=Bs_Train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cffdda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(cctv_val, batch_size=Bs_Train, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00e9b182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iter(model, optimz, data_load, loss_val):\n",
    "    samples = len(data_load.dataset)\n",
    "    model.train()\n",
    "    model.cuda()\n",
    "    model.clean_activation_buffers()\n",
    "    optimz.zero_grad()\n",
    "    for i, (data,_ , target) in enumerate(data_load):\n",
    "        out = F.log_softmax(model(data.cuda()), dim=1)\n",
    "        loss = F.nll_loss(out, target.cuda())\n",
    "        loss.backward()\n",
    "        optimz.step()\n",
    "        optimz.zero_grad()\n",
    "        model.clean_activation_buffers()\n",
    "        if i % 50 == 0:\n",
    "            print('[' +  '{:5}'.format(i * len(data)) + '/' + '{:5}'.format(samples) +\n",
    "                  ' (' + '{:3.0f}'.format(100 * i / len(data_load)) + '%)]  Loss: ' +\n",
    "                  '{:6.4f}'.format(loss.item()))\n",
    "            loss_val.append(loss.item())\n",
    "\n",
    "def evaluate(model, data_load, loss_val):\n",
    "    model.eval()\n",
    "    \n",
    "    samples = len(data_load.dataset)\n",
    "    csamp = 0\n",
    "    tloss = 0\n",
    "    model.clean_activation_buffers()\n",
    "    with torch.no_grad():\n",
    "        for data, _, target in data_load:\n",
    "            output = F.log_softmax(model(data.cuda()), dim=1)\n",
    "            loss = F.nll_loss(output, target.cuda(), reduction='sum')\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            \n",
    "            tloss += loss.item()\n",
    "            csamp += pred.eq(target.cuda()).sum()\n",
    "            model.clean_activation_buffers()\n",
    "    aloss = tloss / samples\n",
    "    loss_val.append(aloss)\n",
    "    print('\\nAverage loss: ' + '{:.4f}'.format(aloss) +\n",
    "          '  Accuracy:' + '{:5}'.format(csamp) + '/' +\n",
    "          '{:5}'.format(samples) + ' (' +\n",
    "          '{:4.2f}'.format(100.0 * csamp / samples) + '%)\\n')\n",
    "    \n",
    "def train_iter_stream(model, optimz, data_load, loss_val, n_clips = 2, n_clip_frames=8):\n",
    "    \"\"\"\n",
    "    In causal mode with stream buffer a single video is fed to the network\n",
    "    using subclips of lenght n_clip_frames. \n",
    "    n_clips*n_clip_frames should be equal to the total number of frames presents\n",
    "    in the video.\n",
    "    \n",
    "    n_clips : number of clips that are used\n",
    "    n_clip_frames : number of frame contained in each clip\n",
    "    \"\"\"\n",
    "    #clean the buffer of activations\n",
    "    samples = len(data_load.dataset)\n",
    "    model.cuda()\n",
    "    model.train()\n",
    "    model.clean_activation_buffers()\n",
    "    optimz.zero_grad()\n",
    "    \n",
    "    for i, (data,_, target) in enumerate(data_load):\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "        l_batch = 0\n",
    "        #backward pass for each clip\n",
    "        for j in range(n_clips):\n",
    "            output = F.log_softmax(model(data[:,:,(n_clip_frames)*(j):(n_clip_frames)*(j+1)]), dim=1)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            loss = F.nll_loss(output, target)/n_clips\n",
    "            loss.backward()\n",
    "        l_batch += loss.item()*n_clips\n",
    "        optimz.step()\n",
    "        optimz.zero_grad()\n",
    "        \n",
    "        #clean the buffer of activations\n",
    "        model.clean_activation_buffers()\n",
    "        if i % 50 == 0:\n",
    "            print('[' +  '{:5}'.format(i * len(data)) + '/' + '{:5}'.format(samples) +\n",
    "                  ' (' + '{:3.0f}'.format(100 * i / len(data_load)) + '%)]  Loss: ' +\n",
    "                  '{:6.4f}'.format(l_batch))\n",
    "            loss_val.append(l_batch)\n",
    "\n",
    "def evaluate_stream(model, data_load, loss_val, n_clips = 2, n_clip_frames=8):\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    samples = len(data_load.dataset)\n",
    "    csamp = 0\n",
    "    tloss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, _, target in data_load:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            model.clean_activation_buffers()\n",
    "            for j in range(n_clips):\n",
    "                output = F.log_softmax(model(data[:,:,(n_clip_frames)*(j):(n_clip_frames)*(j+1)]), dim=1)\n",
    "                loss = F.nll_loss(output, target)\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            tloss += loss.item()\n",
    "            csamp += pred.eq(target).sum()\n",
    "\n",
    "    aloss = tloss /  len(data_load)\n",
    "    loss_val.append(aloss)\n",
    "    print('Average loss: ' + '{:.4f}'.format(aloss) +\n",
    "          '  Accuracy:' + '{:5}'.format(csamp) + '/' +\n",
    "          '{:5}'.format(samples) + ' (' +\n",
    "          '{:4.2f}'.format(100.0 * csamp / samples) + '%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5423062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe4e5d2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[    0/ 8406 (  0%)]  Loss: 3.9833\n",
      "[  800/ 8406 ( 10%)]  Loss: 1.5608\n",
      "[ 1600/ 8406 ( 19%)]  Loss: 1.5167\n",
      "[ 2400/ 8406 ( 29%)]  Loss: 0.5917\n",
      "[ 3200/ 8406 ( 38%)]  Loss: 0.3492\n",
      "[ 4000/ 8406 ( 48%)]  Loss: 0.4045\n",
      "[ 4800/ 8406 ( 57%)]  Loss: 0.2029\n",
      "[ 5600/ 8406 ( 67%)]  Loss: 0.1374\n",
      "[ 6400/ 8406 ( 76%)]  Loss: 0.2290\n",
      "[ 7200/ 8406 ( 86%)]  Loss: 0.3123\n",
      "[ 8000/ 8406 ( 95%)]  Loss: 0.1722\n",
      "Train time: 183.56 seconds\n",
      "\n",
      "Train result\n",
      "Average loss: 0.2094  Accuracy: 7713/ 8406 (91.76%)\n",
      "\n",
      "Validation result\n",
      "Average loss: 0.2412  Accuracy:  844/  933 (90.46%)\n",
      "Validation time: 10.07 seconds\n",
      "\n",
      "Epoch: 2\n",
      "[    0/ 8406 (  0%)]  Loss: 0.0512\n",
      "[  800/ 8406 ( 10%)]  Loss: 0.2617\n",
      "[ 1600/ 8406 ( 19%)]  Loss: 0.0958\n",
      "[ 2400/ 8406 ( 29%)]  Loss: 0.1813\n",
      "[ 3200/ 8406 ( 38%)]  Loss: 0.0537\n",
      "[ 4000/ 8406 ( 48%)]  Loss: 0.0222\n",
      "[ 4800/ 8406 ( 57%)]  Loss: 0.1381\n",
      "[ 5600/ 8406 ( 67%)]  Loss: 0.1003\n",
      "[ 6400/ 8406 ( 76%)]  Loss: 0.2453\n",
      "[ 7200/ 8406 ( 86%)]  Loss: 0.0370\n",
      "[ 8000/ 8406 ( 95%)]  Loss: 0.1624\n",
      "Train time: 183.43 seconds\n",
      "\n",
      "Train result\n",
      "Average loss: 0.0854  Accuracy: 8136/ 8406 (96.79%)\n",
      "\n",
      "Validation result\n",
      "Average loss: 0.1031  Accuracy:  894/  933 (95.82%)\n",
      "Validation time: 10.03 seconds\n",
      "\n",
      "Epoch: 3\n",
      "[    0/ 8406 (  0%)]  Loss: 0.0102\n",
      "[  800/ 8406 ( 10%)]  Loss: 0.1203\n",
      "[ 1600/ 8406 ( 19%)]  Loss: 0.1225\n",
      "[ 2400/ 8406 ( 29%)]  Loss: 0.0108\n",
      "[ 3200/ 8406 ( 38%)]  Loss: 0.0243\n",
      "[ 4000/ 8406 ( 48%)]  Loss: 0.0338\n",
      "[ 4800/ 8406 ( 57%)]  Loss: 0.2442\n",
      "[ 5600/ 8406 ( 67%)]  Loss: 0.0291\n",
      "[ 6400/ 8406 ( 76%)]  Loss: 0.0200\n",
      "[ 7200/ 8406 ( 86%)]  Loss: 0.0154\n",
      "[ 8000/ 8406 ( 95%)]  Loss: 0.2112\n",
      "Train time: 180.03 seconds\n",
      "\n",
      "Train result\n",
      "Average loss: 0.0626  Accuracy: 8287/ 8406 (98.58%)\n",
      "\n",
      "Validation result\n",
      "Average loss: 0.0786  Accuracy:  914/  933 (97.96%)\n",
      "Validation time: 10.26 seconds\n",
      "\n",
      "Epoch: 4\n",
      "[    0/ 8406 (  0%)]  Loss: 0.0545\n",
      "[  800/ 8406 ( 10%)]  Loss: 0.1006\n",
      "[ 1600/ 8406 ( 19%)]  Loss: 0.0091\n",
      "[ 2400/ 8406 ( 29%)]  Loss: 0.0806\n",
      "[ 3200/ 8406 ( 38%)]  Loss: 0.0155\n",
      "[ 4000/ 8406 ( 48%)]  Loss: 0.1704\n",
      "[ 4800/ 8406 ( 57%)]  Loss: 0.2844\n",
      "[ 5600/ 8406 ( 67%)]  Loss: 0.0065\n",
      "[ 6400/ 8406 ( 76%)]  Loss: 0.0269\n",
      "[ 7200/ 8406 ( 86%)]  Loss: 0.1630\n",
      "[ 8000/ 8406 ( 95%)]  Loss: 0.0217\n",
      "Train time: 179.25 seconds\n",
      "\n",
      "Train result\n",
      "Average loss: 0.0589  Accuracy: 8265/ 8406 (98.32%)\n",
      "\n",
      "Validation result\n",
      "Average loss: 0.0665  Accuracy:  917/  933 (98.29%)\n",
      "Validation time:  9.94 seconds\n",
      "\n",
      "Epoch: 5\n",
      "[    0/ 8406 (  0%)]  Loss: 0.5144\n",
      "[  800/ 8406 ( 10%)]  Loss: 0.0126\n",
      "[ 1600/ 8406 ( 19%)]  Loss: 0.0186\n",
      "[ 2400/ 8406 ( 29%)]  Loss: 0.0368\n",
      "[ 3200/ 8406 ( 38%)]  Loss: 0.0130\n",
      "[ 4000/ 8406 ( 48%)]  Loss: 0.0067\n",
      "[ 4800/ 8406 ( 57%)]  Loss: 0.0085\n",
      "[ 5600/ 8406 ( 67%)]  Loss: 0.1588\n",
      "[ 6400/ 8406 ( 76%)]  Loss: 0.0078\n",
      "[ 7200/ 8406 ( 86%)]  Loss: 0.0090\n",
      "[ 8000/ 8406 ( 95%)]  Loss: 0.0133\n",
      "Train time: 179.19 seconds\n",
      "\n",
      "Train result\n",
      "Average loss: 0.0691  Accuracy: 8218/ 8406 (97.76%)\n",
      "\n",
      "Validation result\n",
      "Average loss: 0.0919  Accuracy:  904/  933 (96.89%)\n",
      "Validation time:  9.92 seconds\n",
      "\n",
      "Epoch: 6\n",
      "[    0/ 8406 (  0%)]  Loss: 0.1385\n",
      "[  800/ 8406 ( 10%)]  Loss: 0.0213\n",
      "[ 1600/ 8406 ( 19%)]  Loss: 0.0243\n",
      "[ 2400/ 8406 ( 29%)]  Loss: 0.0136\n",
      "[ 3200/ 8406 ( 38%)]  Loss: 0.0147\n",
      "[ 4000/ 8406 ( 48%)]  Loss: 0.0196\n",
      "[ 4800/ 8406 ( 57%)]  Loss: 0.0685\n",
      "[ 5600/ 8406 ( 67%)]  Loss: 0.0074\n",
      "[ 6400/ 8406 ( 76%)]  Loss: 0.0137\n",
      "[ 7200/ 8406 ( 86%)]  Loss: 0.0768\n",
      "[ 8000/ 8406 ( 95%)]  Loss: 0.0112\n",
      "Train time: 178.44 seconds\n",
      "\n",
      "Train result\n",
      "Average loss: 0.0406  Accuracy: 8289/ 8406 (98.61%)\n",
      "\n",
      "Validation result\n",
      "Average loss: 0.0499  Accuracy:  916/  933 (98.18%)\n",
      "Validation time: 10.61 seconds\n",
      "\n",
      "Epoch: 7\n",
      "[    0/ 8406 (  0%)]  Loss: 0.0118\n",
      "[  800/ 8406 ( 10%)]  Loss: 0.0129\n",
      "[ 1600/ 8406 ( 19%)]  Loss: 0.1267\n",
      "[ 2400/ 8406 ( 29%)]  Loss: 0.0273\n",
      "[ 3200/ 8406 ( 38%)]  Loss: 0.1128\n",
      "[ 4000/ 8406 ( 48%)]  Loss: 0.0116\n",
      "[ 4800/ 8406 ( 57%)]  Loss: 0.0142\n",
      "[ 5600/ 8406 ( 67%)]  Loss: 0.0059\n",
      "[ 6400/ 8406 ( 76%)]  Loss: 0.0078\n",
      "[ 7200/ 8406 ( 86%)]  Loss: 0.0052\n",
      "[ 8000/ 8406 ( 95%)]  Loss: 0.0054\n",
      "Train time: 178.31 seconds\n",
      "\n",
      "Train result\n",
      "Average loss: 0.0307  Accuracy: 8323/ 8406 (99.01%)\n",
      "\n",
      "Validation result\n",
      "Average loss: 0.0443  Accuracy:  918/  933 (98.39%)\n",
      "Validation time: 10.05 seconds\n",
      "\n",
      "Epoch: 8\n",
      "[    0/ 8406 (  0%)]  Loss: 0.0057\n",
      "[  800/ 8406 ( 10%)]  Loss: 0.0109\n",
      "[ 1600/ 8406 ( 19%)]  Loss: 0.1968\n",
      "[ 2400/ 8406 ( 29%)]  Loss: 0.0569\n",
      "[ 3200/ 8406 ( 38%)]  Loss: 0.0053\n",
      "[ 4000/ 8406 ( 48%)]  Loss: 0.0016\n",
      "[ 4800/ 8406 ( 57%)]  Loss: 0.0058\n",
      "[ 5600/ 8406 ( 67%)]  Loss: 0.0010\n",
      "[ 6400/ 8406 ( 76%)]  Loss: 0.1673\n",
      "[ 7200/ 8406 ( 86%)]  Loss: 0.0078\n",
      "[ 8000/ 8406 ( 95%)]  Loss: 0.0130\n",
      "Train time: 181.52 seconds\n",
      "\n",
      "Train result\n",
      "Average loss: 0.0172  Accuracy: 8335/ 8406 (99.16%)\n",
      "\n",
      "Validation result\n",
      "Average loss: 0.0319  Accuracy:  920/  933 (98.61%)\n",
      "Validation time: 10.24 seconds\n",
      "\n",
      "Epoch: 9\n",
      "[    0/ 8406 (  0%)]  Loss: 0.0303\n",
      "[  800/ 8406 ( 10%)]  Loss: 0.0017\n",
      "[ 1600/ 8406 ( 19%)]  Loss: 0.0014\n",
      "[ 2400/ 8406 ( 29%)]  Loss: 0.0020\n",
      "[ 3200/ 8406 ( 38%)]  Loss: 0.0074\n",
      "[ 4000/ 8406 ( 48%)]  Loss: 0.0070\n",
      "[ 4800/ 8406 ( 57%)]  Loss: 0.0300\n",
      "[ 5600/ 8406 ( 67%)]  Loss: 0.0002\n",
      "[ 6400/ 8406 ( 76%)]  Loss: 0.0595\n",
      "[ 7200/ 8406 ( 86%)]  Loss: 0.0157\n",
      "[ 8000/ 8406 ( 95%)]  Loss: 0.0073\n",
      "Train time: 179.91 seconds\n",
      "\n",
      "Train result\n",
      "Average loss: 0.0260  Accuracy: 8341/ 8406 (99.23%)\n",
      "\n",
      "Validation result\n",
      "Average loss: 0.0349  Accuracy:  919/  933 (98.50%)\n",
      "Validation time: 10.07 seconds\n",
      "\n",
      "Epoch: 10\n",
      "[    0/ 8406 (  0%)]  Loss: 0.0017\n",
      "[  800/ 8406 ( 10%)]  Loss: 0.0012\n",
      "[ 1600/ 8406 ( 19%)]  Loss: 0.0003\n",
      "[ 2400/ 8406 ( 29%)]  Loss: 0.0002\n",
      "[ 3200/ 8406 ( 38%)]  Loss: 0.0071\n",
      "[ 4000/ 8406 ( 48%)]  Loss: 0.0553\n",
      "[ 4800/ 8406 ( 57%)]  Loss: 0.0002\n",
      "[ 5600/ 8406 ( 67%)]  Loss: 0.0005\n",
      "[ 6400/ 8406 ( 76%)]  Loss: 0.0003\n",
      "[ 7200/ 8406 ( 86%)]  Loss: 0.0061\n",
      "[ 8000/ 8406 ( 95%)]  Loss: 0.2409\n",
      "Train time: 181.57 seconds\n",
      "\n",
      "Train result\n",
      "Average loss: 0.0114  Accuracy: 8377/ 8406 (99.66%)\n",
      "\n",
      "Validation result\n",
      "Average loss: 0.0208  Accuracy:  927/  933 (99.36%)\n",
      "Validation time: 10.92 seconds\n",
      "\n",
      "Execution time: 2817.73 seconds\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "start_time = time.time()\n",
    "model = MoViNet(_C.MODEL.MoViNetA0, causal = True, pretrained = True )\n",
    "\n",
    "\n",
    "trloss_val, tsloss_val = [], []\n",
    "model.classifier[3] = torch.nn.Conv3d(2048, 51, (1,1,1))\n",
    "optimz = optim.Adam(model.parameters(), lr=0.00005)\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    print('Epoch:', epoch)\n",
    "    train_time = time.time()\n",
    "    train_iter_stream(model, optimz, train_loader, trloss_val)\n",
    "    print('Train time:', '{:5.2f}'.format(time.time() - train_time), 'seconds')\n",
    "    print('\\nTrain result')\n",
    "    evaluate_stream(model, train_loader, tsloss_val)\n",
    "    \n",
    "    print('\\nValidation result')\n",
    "    test_time = time.time()\n",
    "    evaluate_stream(model, val_loader, tsloss_val)\n",
    "    print('Validation time:', '{:5.2f}'.format(time.time() - test_time), 'seconds\\n')\n",
    "    \n",
    "\n",
    "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dbad4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[    0/ 8406 (  0%)]  Loss: 3.8956\n",
      "[  800/ 8406 ( 10%)]  Loss: 1.8962\n",
      "[ 1600/ 8406 ( 19%)]  Loss: 1.2074\n",
      "[ 2400/ 8406 ( 29%)]  Loss: 0.4718\n",
      "[ 3200/ 8406 ( 38%)]  Loss: 0.4290\n",
      "[ 4000/ 8406 ( 48%)]  Loss: 0.2794\n",
      "[ 4800/ 8406 ( 57%)]  Loss: 0.2399\n",
      "[ 5600/ 8406 ( 67%)]  Loss: 0.3048\n",
      "[ 6400/ 8406 ( 76%)]  Loss: 0.2359\n",
      "[ 7200/ 8406 ( 86%)]  Loss: 0.1312\n",
      "[ 8000/ 8406 ( 95%)]  Loss: 0.2485\n",
      "Train time: 188.46 seconds\n",
      "\n",
      "Train result\n",
      "Average loss: 0.1955  Accuracy: 7926/ 8406 (94.29%)\n",
      "\n",
      "Validation result\n",
      "Average loss: 0.2182  Accuracy:  873/  933 (93.57%)\n",
      "Validation time:  8.14 seconds\n",
      "\n",
      "Epoch: 2\n",
      "[    0/ 8406 (  0%)]  Loss: 0.1409\n",
      "[  800/ 8406 ( 10%)]  Loss: 0.3659\n",
      "[ 1600/ 8406 ( 19%)]  Loss: 0.0992\n",
      "[ 2400/ 8406 ( 29%)]  Loss: 0.3001\n",
      "[ 3200/ 8406 ( 38%)]  Loss: 0.0611\n",
      "[ 4000/ 8406 ( 48%)]  Loss: 0.0214\n",
      "[ 4800/ 8406 ( 57%)]  Loss: 0.0618\n",
      "[ 5600/ 8406 ( 67%)]  Loss: 0.0423\n",
      "[ 6400/ 8406 ( 76%)]  Loss: 0.1850\n",
      "[ 7200/ 8406 ( 86%)]  Loss: 0.4628\n",
      "[ 8000/ 8406 ( 95%)]  Loss: 0.0498\n",
      "Train time: 184.90 seconds\n",
      "\n",
      "Train result\n",
      "Average loss: 0.1292  Accuracy: 8099/ 8406 (96.35%)\n",
      "\n",
      "Validation result\n",
      "Average loss: 0.1541  Accuracy:  890/  933 (95.39%)\n",
      "Validation time:  7.91 seconds\n",
      "\n",
      "Epoch: 3\n",
      "[    0/ 8406 (  0%)]  Loss: 0.2502\n",
      "[  800/ 8406 ( 10%)]  Loss: 0.0861\n",
      "[ 1600/ 8406 ( 19%)]  Loss: 0.0240\n",
      "[ 2400/ 8406 ( 29%)]  Loss: 0.0511\n",
      "[ 3200/ 8406 ( 38%)]  Loss: 0.0759\n",
      "[ 4000/ 8406 ( 48%)]  Loss: 0.0209\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "start_time = time.time()\n",
    "model = MoViNet(_C.MODEL.MoViNetA0, causal = False, pretrained = True )\n",
    "\n",
    "\n",
    "trloss_val, tsloss_val = [], []\n",
    "model.classifier[3] = torch.nn.Conv3d(2048, 51, (1,1,1))\n",
    "optimz = optim.Adam(model.parameters(), lr=0.00005)\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    print('Epoch:', epoch)\n",
    "    train_time = time.time()\n",
    "    train_iter_stream(model, optimz, train_loader, trloss_val)\n",
    "    print('Train time:', '{:5.2f}'.format(time.time() - train_time), 'seconds')\n",
    "    print('\\nTrain result')\n",
    "    evaluate_stream(model, train_loader, tsloss_val)\n",
    "    \n",
    "    print('\\nValidation result')\n",
    "    test_time = time.time()\n",
    "    evaluate_stream(model, val_loader, tsloss_val)\n",
    "    print('Validation time:', '{:5.2f}'.format(time.time() - test_time), 'seconds\\n')\n",
    "    \n",
    "\n",
    "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b130bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
