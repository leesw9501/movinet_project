{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "013fcc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch\n",
    "import transforms as T\n",
    "from movinets.config import _C\n",
    "import numpy as np\n",
    "from movinets import MoViNet\n",
    "import random\n",
    "import gc\n",
    "\n",
    "torch.manual_seed(97)\n",
    "num_frames = 16 # 16\n",
    "clip_steps = 2\n",
    "Bs_Train = 16\n",
    "Bs_Test = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64281846",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict=dict()\n",
    "class_dict['normal']=0\n",
    "class_dict['assault']=1\n",
    "class_dict['fight']=2\n",
    "class_dict['burglary']=3\n",
    "class_dict['vandalism']=4\n",
    "class_dict['swoon']=5\n",
    "class_dict['wander']=6\n",
    "class_dict['trespass']=7\n",
    "class_dict['dump']=8\n",
    "class_dict['robbery']=9\n",
    "class_dict['datefight']=10\n",
    "class_dict['kidnap']=11\n",
    "class_dict['drunken']=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca89dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../iterdata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "482b85b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = []\n",
    "#test_data = np.array(test_data)\n",
    "\n",
    "val_label = np.empty((0), 'float')\n",
    "\n",
    "for class_num in range(1,11):\n",
    "    for num in range(1):\n",
    "        path = root + str(class_num) + '/' + str(num)\n",
    "        cap = cv2.VideoCapture(path+'.mp4')\n",
    "        if cap.isOpened():\n",
    "            val_label = np.concatenate((val_label, np.load(path + '.npy')[num_frames-1:]))\n",
    "            img_arr=[]\n",
    "            while True:\n",
    "                ret, img = cap.read()\n",
    "                if ret:\n",
    "                    img_arr.append(img)\n",
    "                    if len(img_arr)==num_frames:\n",
    "                        val_data.append(img_arr.copy())\n",
    "                        del img_arr[0]\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            cap.release()\n",
    "\n",
    "        else:\n",
    "            print('cannot open the file', out_path + '.mp4')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db238864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf54ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "#test_data = np.array(test_data)\n",
    "\n",
    "train_label = np.empty((0), 'float')\n",
    "\n",
    "for class_num in range(1,11):\n",
    "    for num in range(1,4):\n",
    "        path = root + str(class_num) + '/' + str(num)\n",
    "        cap = cv2.VideoCapture(path+'.mp4')\n",
    "        if cap.isOpened():\n",
    "            train_label = np.concatenate((train_label, np.load(path + '.npy')[num_frames-1:]))\n",
    "            img_arr=[]\n",
    "            while True:\n",
    "                ret, img = cap.read()\n",
    "                if ret:\n",
    "                    img_arr.append(img)\n",
    "                    if len(img_arr)==num_frames:\n",
    "                        train_data.append(img_arr.copy())\n",
    "                        del img_arr[0]\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            cap.release()\n",
    "\n",
    "        else:\n",
    "            print('cannot open the file', out_path + '.mp4')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b571670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46133"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f0cceac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46133,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be1b4f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15577"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a302cc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15577,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c2a00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cctv():\n",
    "\n",
    "    def __init__(self, train_data, label_data):\n",
    "        self.train = train_data\n",
    "        self.label = torch.from_numpy(label_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(np.array(self.train[idx]).reshape(3, 16, 172, 172)).float()/255, self.label[idx].long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21b3983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cctv_train = cctv(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd268e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cctv_val = cctv(val_data, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cadfc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(cctv_train, batch_size=Bs_Train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cffdda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(cctv_val, batch_size=Bs_Train, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00e9b182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iter(model, optimz, data_load, loss_val):\n",
    "    samples = len(data_load.dataset)\n",
    "    model.train()\n",
    "    model.cuda()\n",
    "    model.clean_activation_buffers()\n",
    "    optimz.zero_grad()\n",
    "    for i, (data,target) in enumerate(data_load):\n",
    "        out = F.log_softmax(model(data.cuda()), dim=1)\n",
    "        loss = F.nll_loss(out, target.cuda())\n",
    "        loss.backward()\n",
    "        optimz.step()\n",
    "        optimz.zero_grad()\n",
    "        model.clean_activation_buffers()\n",
    "        if i % 50 == 0:\n",
    "            print('[' +  '{:5}'.format(i * len(data)) + '/' + '{:5}'.format(samples) +\n",
    "                  ' (' + '{:3.0f}'.format(100 * i / len(data_load)) + '%)]  Loss: ' +\n",
    "                  '{:6.4f}'.format(loss.item()))\n",
    "            loss_val.append(loss.item())\n",
    "\n",
    "def evaluate(model, data_load, loss_val):\n",
    "    model.eval()\n",
    "    \n",
    "    samples = len(data_load.dataset)\n",
    "    csamp = 0\n",
    "    tloss = 0\n",
    "    model.clean_activation_buffers()\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_load:\n",
    "            output = F.log_softmax(model(data.cuda()), dim=1)\n",
    "            loss = F.nll_loss(output, target.cuda(), reduction='sum')\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            \n",
    "            tloss += loss.item()\n",
    "            csamp += pred.eq(target.cuda()).sum()\n",
    "            model.clean_activation_buffers()\n",
    "    aloss = tloss / samples\n",
    "    loss_val.append(aloss)\n",
    "    print('\\nAverage loss: ' + '{:.4f}'.format(aloss) +\n",
    "          '  Accuracy:' + '{:5}'.format(csamp) + '/' +\n",
    "          '{:5}'.format(samples) + ' (' +\n",
    "          '{:4.2f}'.format(100.0 * csamp / samples) + '%)\\n')\n",
    "    \n",
    "def train_iter_stream(model, optimz, data_load, loss_val, n_clips = 2, n_clip_frames=8):\n",
    "    \"\"\"\n",
    "    In causal mode with stream buffer a single video is fed to the network\n",
    "    using subclips of lenght n_clip_frames. \n",
    "    n_clips*n_clip_frames should be equal to the total number of frames presents\n",
    "    in the video.\n",
    "    \n",
    "    n_clips : number of clips that are used\n",
    "    n_clip_frames : number of frame contained in each clip\n",
    "    \"\"\"\n",
    "    #clean the buffer of activations\n",
    "    samples = len(data_load.dataset)\n",
    "    model.cuda()\n",
    "    model.train()\n",
    "    model.clean_activation_buffers()\n",
    "    optimz.zero_grad()\n",
    "    \n",
    "    for i, (data,target) in enumerate(data_load):\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "        l_batch = 0\n",
    "        #backward pass for each clip\n",
    "        for j in range(n_clips):\n",
    "            output = F.log_softmax(model(data[:,:,(n_clip_frames)*(j):(n_clip_frames)*(j+1)]), dim=1)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            loss = F.nll_loss(output, target)/n_clips\n",
    "            loss.backward()\n",
    "        l_batch += loss.item()*n_clips\n",
    "        optimz.step()\n",
    "        optimz.zero_grad()\n",
    "        \n",
    "        #clean the buffer of activations\n",
    "        model.clean_activation_buffers()\n",
    "        if i % 50 == 0:\n",
    "            print('[' +  '{:5}'.format(i * len(data)) + '/' + '{:5}'.format(samples) +\n",
    "                  ' (' + '{:3.0f}'.format(100 * i / len(data_load)) + '%)]  Loss: ' +\n",
    "                  '{:6.4f}'.format(l_batch))\n",
    "            loss_val.append(l_batch)\n",
    "\n",
    "def evaluate_stream(model, data_load, loss_val, n_clips = 2, n_clip_frames=8):\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    samples = len(data_load.dataset)\n",
    "    csamp = 0\n",
    "    tloss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_load:\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "            model.clean_activation_buffers()\n",
    "            for j in range(n_clips):\n",
    "                output = F.log_softmax(model(data[:,:,(n_clip_frames)*(j):(n_clip_frames)*(j+1)]), dim=1)\n",
    "                loss = F.nll_loss(output, target)\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            tloss += loss.item()\n",
    "            csamp += pred.eq(target).sum()\n",
    "\n",
    "    aloss = tloss /  len(data_load)\n",
    "    loss_val.append(aloss)\n",
    "    print('Average loss: ' + '{:.4f}'.format(aloss) +\n",
    "          '  Accuracy:' + '{:5}'.format(csamp) + '/' +\n",
    "          '{:5}'.format(samples) + ' (' +\n",
    "          '{:4.2f}'.format(100.0 * csamp / samples) + '%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5423062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe4e5d2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[    0/46133 (  0%)]  Loss: 3.9834\n",
      "[  800/46133 (  2%)]  Loss: 1.9554\n",
      "[ 1600/46133 (  3%)]  Loss: 0.4851\n",
      "[ 2400/46133 (  5%)]  Loss: 0.4991\n",
      "[ 3200/46133 (  7%)]  Loss: 1.2882\n",
      "[ 4000/46133 (  9%)]  Loss: 0.6098\n",
      "[ 4800/46133 ( 10%)]  Loss: 0.4481\n",
      "[ 5600/46133 ( 12%)]  Loss: 0.4004\n",
      "[ 6400/46133 ( 14%)]  Loss: 0.2192\n",
      "[ 7200/46133 ( 16%)]  Loss: 0.2114\n",
      "[ 8000/46133 ( 17%)]  Loss: 0.4121\n",
      "[ 8800/46133 ( 19%)]  Loss: 0.2653\n",
      "[ 9600/46133 ( 21%)]  Loss: 0.1765\n",
      "[10400/46133 ( 23%)]  Loss: 0.4481\n",
      "[11200/46133 ( 24%)]  Loss: 0.2212\n",
      "[12000/46133 ( 26%)]  Loss: 0.4911\n",
      "[12800/46133 ( 28%)]  Loss: 0.1420\n",
      "[13600/46133 ( 29%)]  Loss: 0.3025\n",
      "[14400/46133 ( 31%)]  Loss: 0.3325\n",
      "[15200/46133 ( 33%)]  Loss: 0.1026\n",
      "[16000/46133 ( 35%)]  Loss: 0.1801\n",
      "[16800/46133 ( 36%)]  Loss: 0.3496\n",
      "[17600/46133 ( 38%)]  Loss: 0.1834\n",
      "[18400/46133 ( 40%)]  Loss: 0.3587\n",
      "[19200/46133 ( 42%)]  Loss: 0.1381\n",
      "[20000/46133 ( 43%)]  Loss: 0.1414\n",
      "[20800/46133 ( 45%)]  Loss: 0.3612\n",
      "[21600/46133 ( 47%)]  Loss: 0.1720\n",
      "[22400/46133 ( 49%)]  Loss: 0.1084\n",
      "[23200/46133 ( 50%)]  Loss: 0.1047\n",
      "[24000/46133 ( 52%)]  Loss: 0.1761\n",
      "[24800/46133 ( 54%)]  Loss: 0.2335\n",
      "[25600/46133 ( 55%)]  Loss: 0.0528\n",
      "[26400/46133 ( 57%)]  Loss: 0.1084\n",
      "[27200/46133 ( 59%)]  Loss: 0.1726\n",
      "[28000/46133 ( 61%)]  Loss: 0.0752\n",
      "[28800/46133 ( 62%)]  Loss: 0.0387\n",
      "[29600/46133 ( 64%)]  Loss: 0.0599\n",
      "[30400/46133 ( 66%)]  Loss: 0.0576\n",
      "[31200/46133 ( 68%)]  Loss: 0.0455\n",
      "[32000/46133 ( 69%)]  Loss: 0.0120\n",
      "[32800/46133 ( 71%)]  Loss: 0.0709\n",
      "[33600/46133 ( 73%)]  Loss: 0.1283\n",
      "[34400/46133 ( 75%)]  Loss: 0.3965\n",
      "[35200/46133 ( 76%)]  Loss: 0.0423\n",
      "[36000/46133 ( 78%)]  Loss: 0.2432\n",
      "[36800/46133 ( 80%)]  Loss: 0.0643\n",
      "[37600/46133 ( 81%)]  Loss: 0.0887\n",
      "[38400/46133 ( 83%)]  Loss: 0.0191\n",
      "[39200/46133 ( 85%)]  Loss: 0.0403\n",
      "[40000/46133 ( 87%)]  Loss: 0.0409\n",
      "[40800/46133 ( 88%)]  Loss: 0.1524\n",
      "[41600/46133 ( 90%)]  Loss: 0.4034\n",
      "[42400/46133 ( 92%)]  Loss: 0.0596\n",
      "[43200/46133 ( 94%)]  Loss: 0.0309\n",
      "[44000/46133 ( 95%)]  Loss: 0.0087\n",
      "[44800/46133 ( 97%)]  Loss: 0.0422\n",
      "[45600/46133 ( 99%)]  Loss: 0.1150\n",
      "Train time: 985.09 seconds\n",
      "\n",
      "Train result\n",
      "Average loss: 0.1028  Accuracy:44486/46133 (96.43%)\n",
      "\n",
      "Validation result\n",
      "Average loss: 0.7198  Accuracy:11478/15577 (73.69%)\n",
      "Validation time: 164.17 seconds\n",
      "\n",
      "Epoch: 2\n",
      "[    0/46133 (  0%)]  Loss: 0.0061\n",
      "[  800/46133 (  2%)]  Loss: 0.1311\n",
      "[ 1600/46133 (  3%)]  Loss: 0.0978\n",
      "[ 2400/46133 (  5%)]  Loss: 0.0140\n",
      "[ 3200/46133 (  7%)]  Loss: 0.0307\n",
      "[ 4000/46133 (  9%)]  Loss: 0.0579\n",
      "[ 4800/46133 ( 10%)]  Loss: 0.0123\n",
      "[ 5600/46133 ( 12%)]  Loss: 0.0082\n",
      "[ 6400/46133 ( 14%)]  Loss: 0.0342\n",
      "[ 7200/46133 ( 16%)]  Loss: 0.0396\n",
      "[ 8000/46133 ( 17%)]  Loss: 0.0184\n",
      "[ 8800/46133 ( 19%)]  Loss: 0.0054\n",
      "[ 9600/46133 ( 21%)]  Loss: 0.0990\n",
      "[10400/46133 ( 23%)]  Loss: 0.0106\n",
      "[11200/46133 ( 24%)]  Loss: 0.0448\n",
      "[12000/46133 ( 26%)]  Loss: 0.0360\n",
      "[12800/46133 ( 28%)]  Loss: 0.1158\n",
      "[13600/46133 ( 29%)]  Loss: 0.0659\n",
      "[14400/46133 ( 31%)]  Loss: 0.0294\n",
      "[15200/46133 ( 33%)]  Loss: 0.0045\n",
      "[16000/46133 ( 35%)]  Loss: 0.1234\n",
      "[16800/46133 ( 36%)]  Loss: 0.0679\n",
      "[17600/46133 ( 38%)]  Loss: 0.0043\n",
      "[18400/46133 ( 40%)]  Loss: 0.0227\n",
      "[19200/46133 ( 42%)]  Loss: 0.0175\n",
      "[20000/46133 ( 43%)]  Loss: 0.0241\n",
      "[20800/46133 ( 45%)]  Loss: 0.0233\n",
      "[21600/46133 ( 47%)]  Loss: 0.0122\n",
      "[22400/46133 ( 49%)]  Loss: 0.0103\n",
      "[23200/46133 ( 50%)]  Loss: 0.0876\n",
      "[24000/46133 ( 52%)]  Loss: 0.1333\n",
      "[24800/46133 ( 54%)]  Loss: 0.0283\n",
      "[25600/46133 ( 55%)]  Loss: 0.0078\n",
      "[26400/46133 ( 57%)]  Loss: 0.0522\n",
      "[27200/46133 ( 59%)]  Loss: 0.0039\n",
      "[28000/46133 ( 61%)]  Loss: 0.0106\n",
      "[28800/46133 ( 62%)]  Loss: 0.0345\n",
      "[29600/46133 ( 64%)]  Loss: 0.1011\n",
      "[30400/46133 ( 66%)]  Loss: 0.0066\n",
      "[31200/46133 ( 68%)]  Loss: 0.0727\n",
      "[32000/46133 ( 69%)]  Loss: 0.0145\n",
      "[32800/46133 ( 71%)]  Loss: 0.0257\n",
      "[33600/46133 ( 73%)]  Loss: 0.0026\n",
      "[34400/46133 ( 75%)]  Loss: 0.0121\n",
      "[35200/46133 ( 76%)]  Loss: 0.0566\n",
      "[36000/46133 ( 78%)]  Loss: 0.0081\n",
      "[36800/46133 ( 80%)]  Loss: 0.0523\n",
      "[37600/46133 ( 81%)]  Loss: 0.0226\n",
      "[38400/46133 ( 83%)]  Loss: 0.0022\n",
      "[39200/46133 ( 85%)]  Loss: 0.0038\n",
      "[40000/46133 ( 87%)]  Loss: 0.0105\n",
      "[40800/46133 ( 88%)]  Loss: 0.0027\n",
      "[41600/46133 ( 90%)]  Loss: 0.0058\n",
      "[42400/46133 ( 92%)]  Loss: 0.0531\n",
      "[43200/46133 ( 94%)]  Loss: 0.0123\n",
      "[44000/46133 ( 95%)]  Loss: 0.0476\n",
      "[44800/46133 ( 97%)]  Loss: 0.0027\n",
      "[45600/46133 ( 99%)]  Loss: 0.0003\n",
      "Train time: 1011.63 seconds\n",
      "\n",
      "Train result\n",
      "Average loss: 0.0428  Accuracy:45476/46133 (98.58%)\n",
      "\n",
      "Validation result\n",
      "Average loss: 0.9669  Accuracy:10971/15577 (70.43%)\n",
      "Validation time: 148.24 seconds\n",
      "\n",
      "Epoch: 3\n",
      "[    0/46133 (  0%)]  Loss: 0.0470\n",
      "[  800/46133 (  2%)]  Loss: 0.0084\n",
      "[ 1600/46133 (  3%)]  Loss: 0.0107\n",
      "[ 2400/46133 (  5%)]  Loss: 0.0113\n",
      "[ 3200/46133 (  7%)]  Loss: 0.1204\n",
      "[ 4000/46133 (  9%)]  Loss: 0.0090\n",
      "[ 4800/46133 ( 10%)]  Loss: 0.0048\n",
      "[ 5600/46133 ( 12%)]  Loss: 0.0429\n",
      "[ 6400/46133 ( 14%)]  Loss: 0.0034\n",
      "[ 7200/46133 ( 16%)]  Loss: 0.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-2487deb5afbd>\", line 12, in <module>\n",
      "    train_iter_stream(model, optimz, train_loader, trloss_val)\n",
      "  File \"<ipython-input-15-8a1a2c2cf929>\", line 66, in train_iter_stream\n",
      "    output = F.log_softmax(model(data[:,:,(n_clip_frames)*(j):(n_clip_frames)*(j+1)]), dim=1)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"E:\\MoViNet\\movinets\\models.py\", line 651, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"E:\\MoViNet\\movinets\\models.py\", line 642, in _forward_impl\n",
      "    x = self.blocks(x)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"E:\\MoViNet\\movinets\\models.py\", line 509, in forward\n",
      "    x = self.project(x)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"E:\\MoViNet\\movinets\\models.py\", line 262, in forward\n",
      "    x = self._forward(x)\n",
      "  File \"E:\\MoViNet\\movinets\\models.py\", line 242, in _forward\n",
      "    x = self.conv_1(x)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\", line 167, in forward\n",
      "    return F.batch_norm(\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\functional.py\", line 2281, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\ntpath.py\", line 647, in realpath\n",
      "    path = _getfinalpathname(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-2487deb5afbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtrain_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtrain_iter_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrloss_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train time:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'{:5.2f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtrain_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'seconds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-8a1a2c2cf929>\u001b[0m in \u001b[0;36mtrain_iter_stream\u001b[1;34m(model, optimz, data_load, loss_val, n_clips, n_clip_frames)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clips\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clip_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clip_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\MoViNet\\movinets\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\MoViNet\\movinets\\models.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    643\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv7\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\MoViNet\\movinets\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\MoViNet\\movinets\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    261\u001b[0m                              self.kernel_size[-2], self.kernel_size[-1])\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\MoViNet\\movinets\\models.py\u001b[0m in \u001b[0;36m_forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"b c t h w -> (b t) c h w\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"2plus1d\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[1;32m--> 167\u001b[1;33m         return F.batch_norm(\n\u001b[0m\u001b[0;32m    168\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2281\u001b[1;33m     return torch.batch_norm(\n\u001b[0m\u001b[0;32m   2282\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2060\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2062\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2063\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "start_time = time.time()\n",
    "model = MoViNet(_C.MODEL.MoViNetA0, causal = True, pretrained = True )\n",
    "\n",
    "\n",
    "trloss_val, tsloss_val = [], []\n",
    "model.classifier[3] = torch.nn.Conv3d(2048, 51, (1,1,1))\n",
    "optimz = optim.Adam(model.parameters(), lr=0.00005)\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    print('Epoch:', epoch)\n",
    "    train_time = time.time()\n",
    "    train_iter_stream(model, optimz, train_loader, trloss_val)\n",
    "    print('Train time:', '{:5.2f}'.format(time.time() - train_time), 'seconds')\n",
    "    print('\\nTrain result')\n",
    "    evaluate_stream(model, train_loader, tsloss_val)\n",
    "    \n",
    "    print('\\nValidation result')\n",
    "    test_time = time.time()\n",
    "    evaluate_stream(model, val_loader, tsloss_val)\n",
    "    print('Validation time:', '{:5.2f}'.format(time.time() - test_time), 'seconds\\n')\n",
    "    \n",
    "\n",
    "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7f3c50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "[    0/46133 (  0%)]  Loss: 3.9220\n",
      "[  800/46133 (  2%)]  Loss: 2.3162\n",
      "[ 1600/46133 (  3%)]  Loss: 0.9422\n",
      "[ 2400/46133 (  5%)]  Loss: 0.7734\n",
      "[ 3200/46133 (  7%)]  Loss: 1.8449\n",
      "[ 4000/46133 (  9%)]  Loss: 0.5197\n",
      "[ 4800/46133 ( 10%)]  Loss: 0.8906\n",
      "[ 5600/46133 ( 12%)]  Loss: 0.2104\n",
      "[ 6400/46133 ( 14%)]  Loss: 0.2657\n",
      "[ 7200/46133 ( 16%)]  Loss: 0.3611\n",
      "[ 8000/46133 ( 17%)]  Loss: 0.3311\n",
      "[ 8800/46133 ( 19%)]  Loss: 0.1427\n",
      "[ 9600/46133 ( 21%)]  Loss: 0.1573\n",
      "[10400/46133 ( 23%)]  Loss: 0.3278\n",
      "[11200/46133 ( 24%)]  Loss: 0.6164\n",
      "[12000/46133 ( 26%)]  Loss: 0.1304\n",
      "[12800/46133 ( 28%)]  Loss: 0.3962\n",
      "[13600/46133 ( 29%)]  Loss: 0.1417\n",
      "[14400/46133 ( 31%)]  Loss: 0.2173\n",
      "[15200/46133 ( 33%)]  Loss: 0.1017\n",
      "[16000/46133 ( 35%)]  Loss: 0.2791\n",
      "[16800/46133 ( 36%)]  Loss: 0.4590\n",
      "[17600/46133 ( 38%)]  Loss: 0.0645\n",
      "[18400/46133 ( 40%)]  Loss: 0.6147\n",
      "[19200/46133 ( 42%)]  Loss: 0.2104\n",
      "[20000/46133 ( 43%)]  Loss: 0.1216\n",
      "[20800/46133 ( 45%)]  Loss: 0.2513\n",
      "[21600/46133 ( 47%)]  Loss: 0.1438\n",
      "[22400/46133 ( 49%)]  Loss: 0.3268\n",
      "[23200/46133 ( 50%)]  Loss: 0.1625\n",
      "[24000/46133 ( 52%)]  Loss: 0.3796\n",
      "[24800/46133 ( 54%)]  Loss: 0.0722\n",
      "[25600/46133 ( 55%)]  Loss: 1.1676\n",
      "[26400/46133 ( 57%)]  Loss: 0.2323\n",
      "[27200/46133 ( 59%)]  Loss: 0.2466\n",
      "[28000/46133 ( 61%)]  Loss: 0.1376\n",
      "[28800/46133 ( 62%)]  Loss: 0.0814\n",
      "[29600/46133 ( 64%)]  Loss: 0.0273\n",
      "[30400/46133 ( 66%)]  Loss: 0.1400\n",
      "[31200/46133 ( 68%)]  Loss: 0.2295\n",
      "[32000/46133 ( 69%)]  Loss: 0.1261\n",
      "[32800/46133 ( 71%)]  Loss: 0.0820\n",
      "[33600/46133 ( 73%)]  Loss: 0.0460\n",
      "[34400/46133 ( 75%)]  Loss: 0.0943\n",
      "[35200/46133 ( 76%)]  Loss: 0.0961\n",
      "[36000/46133 ( 78%)]  Loss: 0.0098\n",
      "[36800/46133 ( 80%)]  Loss: 0.5337\n",
      "[37600/46133 ( 81%)]  Loss: 0.1161\n",
      "[38400/46133 ( 83%)]  Loss: 0.0827\n",
      "[39200/46133 ( 85%)]  Loss: 0.0280\n",
      "[40000/46133 ( 87%)]  Loss: 0.1985\n",
      "[40800/46133 ( 88%)]  Loss: 0.0308\n",
      "[41600/46133 ( 90%)]  Loss: 0.0278\n",
      "[42400/46133 ( 92%)]  Loss: 0.1379\n",
      "[43200/46133 ( 94%)]  Loss: 0.0131\n",
      "[44000/46133 ( 95%)]  Loss: 0.0399\n",
      "[44800/46133 ( 97%)]  Loss: 0.0077\n",
      "[45600/46133 ( 99%)]  Loss: 0.0612\n",
      "Train time: 921.71 seconds\n",
      "\n",
      "Train result\n",
      "\n",
      "Validation result\n",
      "Average loss: 0.6716  Accuracy:12699/15577 (81.52%)\n",
      "Validation time: 118.28 seconds\n",
      "\n",
      "Epoch: 2\n",
      "[    0/46133 (  0%)]  Loss: 0.0386\n",
      "[  800/46133 (  2%)]  Loss: 0.0331\n",
      "[ 1600/46133 (  3%)]  Loss: 0.0220\n",
      "[ 2400/46133 (  5%)]  Loss: 0.0424\n",
      "[ 3200/46133 (  7%)]  Loss: 0.3945\n",
      "[ 4000/46133 (  9%)]  Loss: 0.1199\n",
      "[ 4800/46133 ( 10%)]  Loss: 0.1230\n",
      "[ 5600/46133 ( 12%)]  Loss: 0.0329\n",
      "[ 6400/46133 ( 14%)]  Loss: 0.0139\n",
      "[ 7200/46133 ( 16%)]  Loss: 0.0609\n",
      "[ 8000/46133 ( 17%)]  Loss: 0.0082\n",
      "[ 8800/46133 ( 19%)]  Loss: 0.0097\n",
      "[ 9600/46133 ( 21%)]  Loss: 0.0082\n",
      "[10400/46133 ( 23%)]  Loss: 0.1660\n",
      "[11200/46133 ( 24%)]  Loss: 0.2099\n",
      "[12000/46133 ( 26%)]  Loss: 0.0391\n",
      "[12800/46133 ( 28%)]  Loss: 0.2098\n",
      "[13600/46133 ( 29%)]  Loss: 0.0223\n",
      "[14400/46133 ( 31%)]  Loss: 0.0555\n",
      "[15200/46133 ( 33%)]  Loss: 0.0459\n",
      "[16000/46133 ( 35%)]  Loss: 0.0088\n",
      "[16800/46133 ( 36%)]  Loss: 0.1195\n",
      "[17600/46133 ( 38%)]  Loss: 0.1013\n",
      "[18400/46133 ( 40%)]  Loss: 0.0424\n",
      "[19200/46133 ( 42%)]  Loss: 0.0122\n",
      "[20000/46133 ( 43%)]  Loss: 0.0121\n",
      "[20800/46133 ( 45%)]  Loss: 0.0462\n",
      "[21600/46133 ( 47%)]  Loss: 0.0390\n",
      "[22400/46133 ( 49%)]  Loss: 0.3099\n",
      "[23200/46133 ( 50%)]  Loss: 0.0205\n",
      "[24000/46133 ( 52%)]  Loss: 0.0016\n",
      "[24800/46133 ( 54%)]  Loss: 0.0013\n",
      "[25600/46133 ( 55%)]  Loss: 0.0116\n",
      "[26400/46133 ( 57%)]  Loss: 0.0134\n",
      "[27200/46133 ( 59%)]  Loss: 0.0238\n",
      "[28000/46133 ( 61%)]  Loss: 0.0028\n",
      "[28800/46133 ( 62%)]  Loss: 0.1183\n",
      "[29600/46133 ( 64%)]  Loss: 0.0287\n",
      "[30400/46133 ( 66%)]  Loss: 0.1267\n",
      "[31200/46133 ( 68%)]  Loss: 0.0051\n",
      "[32000/46133 ( 69%)]  Loss: 0.0795\n",
      "[32800/46133 ( 71%)]  Loss: 0.0042\n",
      "[33600/46133 ( 73%)]  Loss: 0.0075\n",
      "[34400/46133 ( 75%)]  Loss: 0.0036\n",
      "[35200/46133 ( 76%)]  Loss: 0.0057\n",
      "[36000/46133 ( 78%)]  Loss: 0.3451\n",
      "[36800/46133 ( 80%)]  Loss: 0.1739\n",
      "[37600/46133 ( 81%)]  Loss: 0.0063\n",
      "[38400/46133 ( 83%)]  Loss: 0.0240\n",
      "[39200/46133 ( 85%)]  Loss: 0.0029\n",
      "[40000/46133 ( 87%)]  Loss: 0.0051\n",
      "[40800/46133 ( 88%)]  Loss: 0.0037\n",
      "[41600/46133 ( 90%)]  Loss: 0.0031\n",
      "[42400/46133 ( 92%)]  Loss: 0.1234\n",
      "[43200/46133 ( 94%)]  Loss: 0.0114\n",
      "[44000/46133 ( 95%)]  Loss: 0.0258\n",
      "[44800/46133 ( 97%)]  Loss: 0.0193\n",
      "[45600/46133 ( 99%)]  Loss: 0.0162\n",
      "Train time: 977.39 seconds\n",
      "\n",
      "Train result\n",
      "\n",
      "Validation result\n",
      "Average loss: 0.9416  Accuracy:11514/15577 (73.92%)\n",
      "Validation time: 141.30 seconds\n",
      "\n",
      "Epoch: 3\n",
      "[    0/46133 (  0%)]  Loss: 0.0044\n",
      "[  800/46133 (  2%)]  Loss: 0.0160\n",
      "[ 1600/46133 (  3%)]  Loss: 0.0031\n",
      "[ 2400/46133 (  5%)]  Loss: 0.0416\n",
      "[ 3200/46133 (  7%)]  Loss: 0.0536\n",
      "[ 4000/46133 (  9%)]  Loss: 0.0056\n",
      "[ 4800/46133 ( 10%)]  Loss: 0.0270\n",
      "[ 5600/46133 ( 12%)]  Loss: 0.0048\n",
      "[ 6400/46133 ( 14%)]  Loss: 0.0065\n",
      "[ 7200/46133 ( 16%)]  Loss: 0.0262\n",
      "[ 8000/46133 ( 17%)]  Loss: 0.0005\n",
      "[ 8800/46133 ( 19%)]  Loss: 0.0051\n",
      "[ 9600/46133 ( 21%)]  Loss: 0.0421\n",
      "[10400/46133 ( 23%)]  Loss: 0.0017\n",
      "[11200/46133 ( 24%)]  Loss: 0.0048\n",
      "[12000/46133 ( 26%)]  Loss: 0.0757\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "start_time = time.time()\n",
    "model = MoViNet(_C.MODEL.MoViNetA0, causal = False, pretrained = True )\n",
    "\n",
    "\n",
    "trloss_val, tsloss_val = [], []\n",
    "model.classifier[3] = torch.nn.Conv3d(2048, 51, (1,1,1))\n",
    "optimz = optim.Adam(model.parameters(), lr=0.00005)\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    print('Epoch:', epoch)\n",
    "    train_time = time.time()\n",
    "    train_iter_stream(model, optimz, train_loader, trloss_val)\n",
    "    print('Train time:', '{:5.2f}'.format(time.time() - train_time), 'seconds')\n",
    "    print('\\nTrain result')\n",
    "    #evaluate_stream(model, train_loader, tsloss_val)\n",
    "    \n",
    "    print('\\nValidation result')\n",
    "    test_time = time.time()\n",
    "    evaluate_stream(model, val_loader, tsloss_val)\n",
    "    print('Validation time:', '{:5.2f}'.format(time.time() - test_time), 'seconds\\n')\n",
    "    \n",
    "\n",
    "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b130bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=[1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b765542",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75112641",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrlist=[]\n",
    "for i in range(6,11):\n",
    "    arrlist.append(np.array(arr))\n",
    "    del arr[0]\n",
    "    arr.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf206fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a59786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
