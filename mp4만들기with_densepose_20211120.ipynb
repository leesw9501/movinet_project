{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a95d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import xmltodict\n",
    "import json\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine.defaults import DefaultPredictor\n",
    "from densepose import add_densepose_config\n",
    "\n",
    "from densepose.vis.bounding_box import BoundingBoxVisualizer\n",
    "from densepose.vis.extractor import create_extractor\n",
    "from densepose.vis.densepose_results import (\n",
    "    DensePoseResultsContourVisualizer,\n",
    "    DensePoseResultsFineSegmentationVisualizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c56ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pose_extractor():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        initalize with config of detectron2 densepose\n",
    "        \"\"\"\n",
    "        config_fpath = \"configs/densepose_rcnn_R_50_FPN_s1x.yaml\"\n",
    "        weight_fpath = \"densepose_rcnn_R_50_FPN_s1x.pkl\"\n",
    "        self.output_types = [\"u\", \"v\"]           # select in [u, v, coarse, fine]\n",
    "\n",
    "        # setting cfg\n",
    "        opts = []\n",
    "        opts.append(\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\")\n",
    "        opts.append(str(0.8))\n",
    "        cfg = get_cfg()\n",
    "        add_densepose_config(cfg)\n",
    "        cfg.merge_from_file(config_fpath)\n",
    "        cfg.merge_from_list(opts)\n",
    "        cfg.MODEL.WEIGHTS = weight_fpath\n",
    "        cfg.freeze()\n",
    "\n",
    "        # predictor\n",
    "        self.predictor = DefaultPredictor(cfg)\n",
    "\n",
    "\n",
    "    def __call__(self, img):\n",
    "        with torch.no_grad():\n",
    "            output_dict = dict()\n",
    "            outputs = self.predictor(img)[\"instances\"]\n",
    "\n",
    "            # if any objs isn't detected, return empty dict\n",
    "            if len(outputs) == 0: return output_dict\n",
    "\n",
    "            # get bnd box\n",
    "            bnd_outputs = outputs.get(\"pred_boxes\")\n",
    "            output_dict[\"pred_boxes\"] = bnd_outputs\n",
    "\n",
    "            # get selected features\n",
    "            pose_outputs = outputs.get(\"pred_densepose\")\n",
    "            for key in self.output_types:\n",
    "                output_dict[key]  = getattr(pose_outputs, key)\n",
    "            output_dict[\"instances\"] = self.predictor(img)[\"instances\"]\n",
    "\n",
    "            return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92179b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVisualizer():\n",
    "    def __init__(self, visualizers):\n",
    "        \"\"\"\n",
    "        pick visual kinds that you wank,\n",
    "        then this instance give the img with visual information\n",
    "        dp_contour: basic chart spreaded over the body\n",
    "        dp_segm: segmentation to parts of body\n",
    "        bbox: bnding box\n",
    "        \"\"\"\n",
    "        vis_dict = {\n",
    "            \"dp_contour\": DensePoseResultsContourVisualizer,\n",
    "            \"dp_segm\": DensePoseResultsFineSegmentationVisualizer,\n",
    "            \"bbox\": BoundingBoxVisualizer,\n",
    "        }\n",
    "\n",
    "        self.visualizers = []\n",
    "        self.extractors = []\n",
    "        for vis_str in visualizers:\n",
    "            vis = vis_dict[vis_str]()\n",
    "            self.visualizers.append(vis)\n",
    "            self.extractors.append(create_extractor(vis))\n",
    "\n",
    "    def visualize(self, img_bgr, outputs, img_to_gray=False):\n",
    "        img = img_bgr\n",
    "        for i in outputs:\n",
    "            if i==\"instances\":\n",
    "                if img_to_gray:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                else:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                data = self._extract_data(outputs[\"instances\"])\n",
    "                \n",
    "                for i, visualizer in enumerate(self.visualizers):\n",
    "                    img = visualizer.visualize(img, data[i])\n",
    "        return img\n",
    "\n",
    "    def _extract_data(self, outputs):\n",
    "        datas = []\n",
    "        for extractor in self.extractors:\n",
    "            # TODO plz chk None is ok to place here\n",
    "            data = extractor(outputs, None)\n",
    "            datas.append(data)\n",
    "        return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a20fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01.폭행(assult)\n",
      "outsidedoor_01\n",
      "outsidedoor_02\n",
      "outsidedoor_03\n",
      "outsidedoor_04\n",
      "02.싸움(fight)\n",
      "outsidedoor_01\n",
      "outsidedoor_02\n",
      "outsidedoor_03\n",
      "outsidedoor_04\n",
      "03.절도(burglary)\n",
      "outsidedoor_01\n",
      "outsidedoor_02\n",
      "outsidedoor_03\n",
      "outsidedoor_04\n",
      "04.기물파손(vandalism)\n",
      "outsidedoor_01\n",
      "outsidedoor_02\n",
      "outsidedoor_03\n",
      "outsidedoor_04\n",
      "05.실신(swoon)\n",
      "outsidedoor_01\n",
      "outsidedoor_02\n",
      "outsidedoor_03\n",
      "outsidedoor_04\n",
      "06.배회(wander)\n",
      "outsidedoor_01\n",
      "outsidedoor_02\n",
      "outsidedoor_03\n",
      "outsidedoor_04\n",
      "07.침입(trespass)\n",
      "outsidedoor_01\n",
      "outsidedoor_02\n",
      "outsidedoor_03\n",
      "outsidedoor_04\n",
      "08.투기(dump)\n",
      "outsidedoor_01\n",
      "outsidedoor_02\n",
      "outsidedoor_03\n",
      "outsidedoor_04\n",
      "09.강도(robbery)\n",
      "outsidedoor_01\n",
      "outsidedoor_02\n",
      "outsidedoor_03\n",
      "outsidedoor_04\n",
      "10.데이트폭력및추행(datefight)\n",
      "outsidedoor_01\n",
      "outsidedoor_02\n",
      "outsidedoor_03\n",
      "outsidedoor_04\n",
      "11.납치(kidnap)\n",
      "outsidedoor_01\n",
      "outsidedoor_02\n",
      "outsidedoor_03\n",
      "outsidedoor_04\n",
      "12.주취행동(drunken)\n",
      "outsidedoor_01\n",
      "outsidedoor_02\n",
      "outsidedoor_03\n",
      "outsidedoor_04\n"
     ]
    }
   ],
   "source": [
    "dir_dict=dict()\n",
    "root = './이상행동 CCTV 영상'\n",
    "class_list = os.listdir(root)\n",
    "\n",
    "for class_folder in class_list:\n",
    "    print(class_folder)\n",
    "    dir_dict[class_folder]=[]\n",
    "    place_list = os.listdir(root + '/'+ class_folder)\n",
    "    for place_num in place_list:\n",
    "        print(place_num)\n",
    "        num_list = os.listdir(root + '/'+ class_folder + '/'+ place_num)\n",
    "        for num in num_list:\n",
    "            #print(num)\n",
    "            file_list = os.listdir(root + '/'+ class_folder + '/'+ place_num + '/'+ num)\n",
    "            for file in file_list:\n",
    "                #print(file)\n",
    "                if(file[-4:]=='.mp4'):\n",
    "                    dir_dict[class_folder].append(root + '/'+ class_folder + '/'+ place_num + '/'+ num + '/'+ file[:-4])\n",
    "                #print(file[:-4])\n",
    "                #print(file[-4:]=='.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4584bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict=dict()\n",
    "class_dict['normal']=0\n",
    "class_dict['assault']=1\n",
    "class_dict['fight']=2\n",
    "class_dict['burglary']=3\n",
    "class_dict['vandalism']=4\n",
    "class_dict['swoon']=5\n",
    "class_dict['wander']=6\n",
    "class_dict['trespass']=7\n",
    "class_dict['dump']=8\n",
    "class_dict['robbery']=9\n",
    "class_dict['datefight']=10\n",
    "class_dict['kidnap']=11\n",
    "class_dict['drunken']=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f19c3b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_mp4_label(file_path, out_path, num_seqence=16, fps_setting=5):\n",
    "    xml_path = file_path + '.xml'\n",
    "    video_file = file_path + '.mp4'\n",
    "    num_seq = num_seqence\n",
    "    fps_set = fps_setting\n",
    "    resize_width = 172\n",
    "    resize_height = 172\n",
    "\n",
    "    # xml 파싱\n",
    "    f = open(xml_path, 'r')\n",
    "    read = f.read()\n",
    "    dict2_type = xmltodict.parse(read)\n",
    "\n",
    "    key_pos = [0, 0]\n",
    "\n",
    "    if type(dict2_type['annotation']['object']) == type([]):\n",
    "        for obj in range(len(dict2_type['annotation']['object'])):\n",
    "            key_pos[0] += int(dict2_type['annotation']['object'][obj]['position']['keypoint']['x'])\n",
    "            key_pos[1] += int(dict2_type['annotation']['object'][obj]['position']['keypoint']['y'])\n",
    "        key_pos[0] = int(key_pos[0] / len(dict2_type['annotation']['object']))\n",
    "        key_pos[1] = int(key_pos[1] / len(dict2_type['annotation']['object']))\n",
    "    else:\n",
    "        key_pos[0] += int(dict2_type['annotation']['object']['position']['keypoint']['x'])\n",
    "        key_pos[1] += int(dict2_type['annotation']['object']['position']['keypoint']['y'])\n",
    "\n",
    "    st = dict2_type['annotation']['event']['starttime'].split(':')\n",
    "    du = dict2_type['annotation']['event']['duration'].split(':')\n",
    "\n",
    "    if len(st) == 3:\n",
    "        stint = int(((float(st[0]) * 3600) + (float(st[1]) * 60) + float(st[2])) * int(\n",
    "            dict2_type['annotation']['header']['fps']))\n",
    "    else:\n",
    "        stint = int(((float(st[0]) * 60) + float(st[1])) * int(dict2_type['annotation']['header']['fps']))\n",
    "    if len(du) == 3:\n",
    "        etint = stint + int(((float(du[0]) * 3600) + (float(du[1]) * 60) + float(du[2])) * int(\n",
    "            dict2_type['annotation']['header']['fps']))\n",
    "    else:\n",
    "        etint = stint + int(((float(du[0]) * 60) + float(du[1])) * int(dict2_type['annotation']['header']['fps']))\n",
    "\n",
    "    # 크롭 및 리사이즈\n",
    "    width = int(dict2_type['annotation']['size']['width'])\n",
    "    height = int(dict2_type['annotation']['size']['height'])\n",
    "    depth = int(dict2_type['annotation']['size']['depth'])\n",
    "\n",
    "    if width > height:\n",
    "        low = height\n",
    "    else:\n",
    "        low = width\n",
    "\n",
    "    xs = key_pos[0] - int(low / 2)\n",
    "    xe = key_pos[0] + int(low / 2)\n",
    "    ys = key_pos[1] - int(low / 2)\n",
    "    ye = key_pos[1] + int(low / 2)\n",
    "\n",
    "    if xs < 0:\n",
    "        xe = xe - xs\n",
    "        xs = 0\n",
    "    if ys < 0:\n",
    "        ye = ye - ys\n",
    "        ys = 0\n",
    "    if xe > width:\n",
    "        xs = xs - (xe - width)\n",
    "        xe = width\n",
    "    if ye > height:\n",
    "        ys = ys - (ye - height)\n",
    "        ye = height\n",
    "\n",
    "\n",
    "    fps_dev = int(int(dict2_type['annotation']['header']['fps']) / fps_set)\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "    label = []\n",
    "    cla = class_dict[dict2_type['annotation']['event']['eventname']]\n",
    "    i = 0\n",
    "\n",
    "    out = cv2.VideoWriter(filename=out_path + '.mp4', fourcc=cv2.VideoWriter_fourcc(*'DIVX'),\n",
    "                          fps=fps_setting, frameSize=(resize_width, resize_height), isColor=True)\n",
    "    if not out.isOpened():\n",
    "        print('out File open failed!', out_path + '.mp4')\n",
    "\n",
    "    # densepose extractor\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    extractor = pose_extractor()\n",
    "\n",
    "    # for visulization\n",
    "    # cv2.namedWindow(\"test\", cv2.WINDOW_NORMAL)\n",
    "    start_time = time.time()\n",
    "    if cap.isOpened():\n",
    "        while True:\n",
    "            i += 1\n",
    "            ret, img = cap.read()\n",
    "            if ret:\n",
    "                if i % fps_dev == 0:\n",
    "\n",
    "                    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "                    \n",
    "                    cropped_img = img[ys: ye, xs: xe]\n",
    "                    resized_img = cv2.resize(cropped_img, dsize=(resize_width, resize_height),\n",
    "                                             interpolation=cv2.INTER_AREA)\n",
    "                    \n",
    "                    pose_output = extractor(resized_img)\n",
    "                    visualizer = SimpleVisualizer([\"dp_contour\"])\n",
    "                    post_img = visualizer.visualize(resized_img, pose_output)\n",
    "                    \n",
    "                    out.write(post_img)\n",
    "                    plt.close('all')\n",
    "                    #print(post_img.shape)\n",
    "                    \n",
    "                    #cv2.imshow(\"test\", post_img)\n",
    "                    #cv2.waitKey(0)\n",
    "                    \n",
    "\n",
    "                    #key_pos = [0, 0]\n",
    "\n",
    "                    # for visual\n",
    "                    '''\n",
    "                    if pose_output:\n",
    "                        print(pose_output)\n",
    "                        for idx in range(len(pose_output[\"pred_boxes\"])):\n",
    "                            xyxy = pose_output[\"pred_boxes\"].tensor[idx]\n",
    "                            key_pos[0] += int((xyxy[0]+xyxy[2])/2)\n",
    "                            key_pos[1] += int((xyxy[1]+xyxy[3])/2)\n",
    "                            \n",
    "                            cv2.rectangle(post_img, (int(xyxy[0]), int(xyxy[1]), int(xyxy[2] - xyxy[0]), int(xyxy[3] - xyxy[1])),\n",
    "                                          (18, 127, 15), 5)\n",
    "                        key_pos[0] = int(key_pos[0] / len(pose_output[\"pred_boxes\"]))\n",
    "                        key_pos[1] = int(key_pos[1] / len(pose_output[\"pred_boxes\"]))\n",
    "                    print(key_pos)\n",
    "                    cv2.imshow(\"test\", post_img)\n",
    "                    cv2.waitKey(0)\n",
    "                    break\n",
    "                    '''\n",
    "                    # cv2.imshow(\"test\", img)\n",
    "                    # out.write(resized_img)\n",
    "                    # if cv2.waitKey(1) == 27:\n",
    "                    #     break\n",
    "\n",
    "                    if i > stint and i < etint:\n",
    "                        label.append(cla)\n",
    "                    else:\n",
    "                        label.append(0)\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                    #print(i, time.time()-start_time)\n",
    "                    gc.collect()\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "    else:\n",
    "        print('cannot open the file', out_path + '.mp4')\n",
    "\n",
    "    label2 = np.array(label, dtype=np.uint8)\n",
    "\n",
    "    np.save(out_path + '.npy', label2)\n",
    "    print('success', out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72020d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 150\n",
      "success ./iterdata/1/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\densepose\\vis\\densepose_results.py:133: UserWarning: No contour levels were found within the data range.\n",
      "  plt.contour(u, self.levels, extent=extent, **self.plot_args)\n",
      "E:\\densepose\\vis\\densepose_results.py:134: UserWarning: No contour levels were found within the data range.\n",
      "  plt.contour(v, self.levels, extent=extent, **self.plot_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success ./iterdata/1/1\n",
      "success ./iterdata/1/2\n",
      "success ./iterdata/1/3\n",
      "success ./iterdata/1/4\n",
      "success ./iterdata/1/5\n",
      "success ./iterdata/1/6\n",
      "success ./iterdata/1/7\n",
      "success ./iterdata/1/8\n",
      "success ./iterdata/1/9\n",
      "success ./iterdata/1/10\n",
      "success ./iterdata/1/11\n",
      "success ./iterdata/1/12\n",
      "success ./iterdata/1/13\n",
      "success ./iterdata/1/14\n",
      "success ./iterdata/1/15\n",
      "success ./iterdata/1/16\n",
      "success ./iterdata/1/17\n",
      "success ./iterdata/1/18\n",
      "success ./iterdata/1/19\n",
      "success ./iterdata/1/20\n",
      "success ./iterdata/1/21\n",
      "success ./iterdata/1/22\n",
      "success ./iterdata/1/23\n",
      "success ./iterdata/1/24\n",
      "success ./iterdata/1/25\n",
      "success ./iterdata/1/26\n",
      "success ./iterdata/1/27\n",
      "success ./iterdata/1/28\n",
      "success ./iterdata/1/29\n",
      "success ./iterdata/1/30\n",
      "success ./iterdata/1/31\n",
      "success ./iterdata/1/32\n",
      "success ./iterdata/1/33\n",
      "success ./iterdata/1/34\n",
      "success ./iterdata/1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-67c3fbabd636>\", line 6, in <module>\n",
      "    mk_mp4_label(file_path = path, out_path = './iterdata/'+str(n+1)+'/'+str(video_num), num_seqence=16, fps_setting=5)\n",
      "  File \"<ipython-input-6-201550d00685>\", line 101, in mk_mp4_label\n",
      "    pose_output = extractor(resized_img)\n",
      "  File \"<ipython-input-2-1813ca0de336>\", line 28, in __call__\n",
      "    outputs = self.predictor(img)[\"instances\"]\n",
      "  File \"e:\\detectron2\\detectron2\\engine\\defaults.py\", line 317, in __call__\n",
      "    predictions = self.model([inputs])[0]\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"e:\\detectron2\\detectron2\\modeling\\meta_arch\\rcnn.py\", line 146, in forward\n",
      "    return self.inference(batched_inputs)\n",
      "  File \"e:\\detectron2\\detectron2\\modeling\\meta_arch\\rcnn.py\", line 204, in inference\n",
      "    proposals, _ = self.proposal_generator(images, features, None)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"e:\\detectron2\\detectron2\\modeling\\proposal_generator\\rpn.py\", line 477, in forward\n",
      "    proposals = self.predict_proposals(\n",
      "  File \"e:\\detectron2\\detectron2\\modeling\\proposal_generator\\rpn.py\", line 503, in predict_proposals\n",
      "    return find_top_rpn_proposals(\n",
      "  File \"e:\\detectron2\\detectron2\\modeling\\proposal_generator\\proposal_utils.py\", line 101, in find_top_rpn_proposals\n",
      "    if not valid_mask.all():\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-67c3fbabd636>\", line 6, in <module>\n",
      "    mk_mp4_label(file_path = path, out_path = './iterdata/'+str(n+1)+'/'+str(video_num), num_seqence=16, fps_setting=5)\n",
      "  File \"<ipython-input-6-201550d00685>\", line 101, in mk_mp4_label\n",
      "    pose_output = extractor(resized_img)\n",
      "  File \"<ipython-input-2-1813ca0de336>\", line 28, in __call__\n",
      "    outputs = self.predictor(img)[\"instances\"]\n",
      "  File \"e:\\detectron2\\detectron2\\engine\\defaults.py\", line 317, in __call__\n",
      "    predictions = self.model([inputs])[0]\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"e:\\detectron2\\detectron2\\modeling\\meta_arch\\rcnn.py\", line 146, in forward\n",
      "    return self.inference(batched_inputs)\n",
      "  File \"e:\\detectron2\\detectron2\\modeling\\meta_arch\\rcnn.py\", line 204, in inference\n",
      "    proposals, _ = self.proposal_generator(images, features, None)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1051, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"e:\\detectron2\\detectron2\\modeling\\proposal_generator\\rpn.py\", line 477, in forward\n",
      "    proposals = self.predict_proposals(\n",
      "  File \"e:\\detectron2\\detectron2\\modeling\\proposal_generator\\rpn.py\", line 503, in predict_proposals\n",
      "    return find_top_rpn_proposals(\n",
      "  File \"e:\\detectron2\\detectron2\\modeling\\proposal_generator\\proposal_utils.py\", line 101, in find_top_rpn_proposals\n",
      "    if not valid_mask.all():\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2063, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\USER001\\anaconda3\\envs\\tf24_gpu\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-67c3fbabd636>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdir_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_n\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mmk_mp4_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./iterdata/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_seqence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfps_setting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[0mvideo_num\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-201550d00685>\u001b[0m in \u001b[0;36mmk_mp4_label\u001b[1;34m(file_path, out_path, num_seqence, fps_setting)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                     \u001b[0mpose_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresized_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m                     \u001b[0mvisualizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSimpleVisualizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dp_contour\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-1813ca0de336>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0moutput_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"instances\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\detectron2\\detectron2\\engine\\defaults.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, original_image)\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"height\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"width\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\detectron2\\detectron2\\modeling\\meta_arch\\rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, batched_inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\detectron2\\detectron2\\modeling\\meta_arch\\rcnn.py\u001b[0m in \u001b[0;36minference\u001b[1;34m(self, batched_inputs, detected_instances, do_postprocess)\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproposal_generator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 \u001b[0mproposals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproposal_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\detectron2\\detectron2\\modeling\\proposal_generator\\rpn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, images, features, gt_instances)\u001b[0m\n\u001b[0;32m    476\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m         proposals = self.predict_proposals(\n\u001b[0m\u001b[0;32m    478\u001b[0m             \u001b[0manchors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_objectness_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_anchor_deltas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\detectron2\\detectron2\\modeling\\proposal_generator\\rpn.py\u001b[0m in \u001b[0;36mpredict_proposals\u001b[1;34m(self, anchors, pred_objectness_logits, pred_anchor_deltas, image_sizes)\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mpred_proposals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decode_proposals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manchors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_anchor_deltas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             return find_top_rpn_proposals(\n\u001b[0m\u001b[0;32m    504\u001b[0m                 \u001b[0mpred_proposals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\detectron2\\detectron2\\modeling\\proposal_generator\\proposal_utils.py\u001b[0m in \u001b[0;36mfind_top_rpn_proposals\u001b[1;34m(proposals, pred_objectness_logits, image_sizes, nms_thresh, pre_nms_topk, post_nms_topk, min_box_size, training)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mvalid_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores_per_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalid_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2060\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[1;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[0;32m   3360\u001b[0m                         \u001b[0masy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0masync_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0masy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2062\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2063\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2060\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TypeError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[1;34m(coro)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \"\"\"\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mcoro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[1;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple)\u001b[0m\n\u001b[0;32m   3167\u001b[0m                     \u001b[0minteractivity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'async'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3169\u001b[1;33m                 has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\u001b[0m\u001b[0;32m   3170\u001b[0m                        interactivity=interactivity, compiler=compiler, result=result)\n\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[1;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[0;32m   3378\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3379\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_before_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3380\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3381\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2062\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2063\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1140\u001b[0m         \u001b[0mchained_exc_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m             formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n\u001b[0m\u001b[0;32m   1143\u001b[0m                                                                      chained_exceptions_tb_offset)\n\u001b[0;32m   1144\u001b[0m             \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf24_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "for n, class_n in enumerate(dir_dict):\n",
    "    if n==0:\n",
    "        print(n+1, len(dir_dict[class_n]))\n",
    "        video_num=0\n",
    "        for path in dir_dict[class_n]:\n",
    "            mk_mp4_label(file_path = path, out_path = './iterdata/'+str(n+1)+'/'+str(video_num), num_seqence=16, fps_setting=5)\n",
    "            video_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd19fb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\densepose\\vis\\densepose_results.py:133: UserWarning: No contour levels were found within the data range.\n",
      "  plt.contour(u, self.levels, extent=extent, **self.plot_args)\n",
      "E:\\densepose\\vis\\densepose_results.py:134: UserWarning: No contour levels were found within the data range.\n",
      "  plt.contour(v, self.levels, extent=extent, **self.plot_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success ./iterdata/1/36\n",
      "success ./iterdata/1/37\n",
      "success ./iterdata/1/38\n",
      "success ./iterdata/1/39\n",
      "success ./iterdata/1/40\n",
      "success ./iterdata/1/41\n",
      "success ./iterdata/1/42\n",
      "success ./iterdata/1/43\n",
      "success ./iterdata/1/44\n",
      "success ./iterdata/1/45\n",
      "success ./iterdata/1/46\n",
      "success ./iterdata/1/47\n",
      "success ./iterdata/1/48\n",
      "success ./iterdata/1/49\n",
      "success ./iterdata/1/50\n",
      "success ./iterdata/1/51\n",
      "success ./iterdata/1/52\n",
      "success ./iterdata/1/53\n",
      "success ./iterdata/1/54\n",
      "success ./iterdata/1/55\n",
      "success ./iterdata/1/56\n",
      "success ./iterdata/1/57\n",
      "success ./iterdata/1/58\n",
      "success ./iterdata/1/59\n",
      "success ./iterdata/1/60\n",
      "success ./iterdata/1/61\n",
      "success ./iterdata/1/62\n",
      "success ./iterdata/1/63\n",
      "success ./iterdata/1/64\n",
      "success ./iterdata/1/65\n",
      "success ./iterdata/1/66\n",
      "success ./iterdata/1/67\n",
      "success ./iterdata/1/68\n",
      "success ./iterdata/1/69\n",
      "success ./iterdata/1/70\n",
      "success ./iterdata/1/71\n",
      "success ./iterdata/1/72\n",
      "success ./iterdata/1/73\n",
      "success ./iterdata/1/74\n",
      "success ./iterdata/1/75\n",
      "success ./iterdata/1/76\n",
      "success ./iterdata/1/77\n",
      "success ./iterdata/1/78\n",
      "success ./iterdata/1/79\n",
      "success ./iterdata/1/80\n",
      "success ./iterdata/1/81\n",
      "success ./iterdata/1/82\n",
      "success ./iterdata/1/83\n",
      "success ./iterdata/1/84\n",
      "success ./iterdata/1/85\n",
      "success ./iterdata/1/86\n",
      "success ./iterdata/1/87\n",
      "success ./iterdata/1/88\n",
      "success ./iterdata/1/89\n",
      "success ./iterdata/1/90\n",
      "success ./iterdata/1/91\n",
      "success ./iterdata/1/92\n",
      "success ./iterdata/1/93\n",
      "success ./iterdata/1/94\n",
      "success ./iterdata/1/95\n",
      "success ./iterdata/1/96\n",
      "success ./iterdata/1/97\n",
      "success ./iterdata/1/98\n",
      "success ./iterdata/1/99\n",
      "success ./iterdata/1/100\n",
      "success ./iterdata/1/101\n",
      "success ./iterdata/1/102\n",
      "success ./iterdata/1/103\n",
      "success ./iterdata/1/104\n",
      "success ./iterdata/1/105\n",
      "success ./iterdata/1/106\n",
      "success ./iterdata/1/107\n",
      "success ./iterdata/1/108\n",
      "success ./iterdata/1/109\n",
      "success ./iterdata/1/110\n",
      "success ./iterdata/1/111\n",
      "success ./iterdata/1/112\n",
      "success ./iterdata/1/113\n",
      "success ./iterdata/1/114\n",
      "success ./iterdata/1/115\n",
      "success ./iterdata/1/116\n",
      "success ./iterdata/1/117\n",
      "success ./iterdata/1/118\n",
      "success ./iterdata/1/119\n",
      "success ./iterdata/1/120\n",
      "success ./iterdata/1/121\n",
      "success ./iterdata/1/122\n",
      "success ./iterdata/1/123\n",
      "success ./iterdata/1/124\n",
      "success ./iterdata/1/125\n",
      "success ./iterdata/1/126\n",
      "success ./iterdata/1/127\n",
      "success ./iterdata/1/128\n",
      "success ./iterdata/1/129\n",
      "success ./iterdata/1/130\n",
      "success ./iterdata/1/131\n",
      "success ./iterdata/1/132\n",
      "success ./iterdata/1/133\n",
      "success ./iterdata/1/134\n",
      "success ./iterdata/1/135\n",
      "success ./iterdata/1/136\n",
      "success ./iterdata/1/137\n",
      "success ./iterdata/1/138\n",
      "success ./iterdata/1/139\n",
      "success ./iterdata/1/140\n",
      "success ./iterdata/1/141\n",
      "success ./iterdata/1/142\n",
      "success ./iterdata/1/143\n",
      "success ./iterdata/1/144\n",
      "success ./iterdata/1/145\n",
      "success ./iterdata/1/146\n",
      "success ./iterdata/1/147\n",
      "success ./iterdata/1/148\n",
      "success ./iterdata/1/149\n"
     ]
    }
   ],
   "source": [
    "for n, class_n in enumerate(dir_dict):\n",
    "    if n==0:\n",
    "        print(n+1, len(dir_dict[class_n]))\n",
    "        video_num=0\n",
    "        for path in dir_dict[class_n]:\n",
    "            if video_num>35:\n",
    "                mk_mp4_label(file_path = path, out_path = './iterdata/'+str(n+1)+'/'+str(video_num), num_seqence=16, fps_setting=5)\n",
    "            video_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df13cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
